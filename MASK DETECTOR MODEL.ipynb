{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e43595dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MASK DETECTOR MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45ab6a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a4c6ed",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66bba38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#location of your dataset\n",
    "\n",
    "address = \"C:/Users/91808/Downloads/SPK IIIT/datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd567b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Folder  WithMask\n",
      "Loaded Folder  WithoutMask\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "target = []\n",
    "for i in [\"WithMask\",\"WithoutMask\"]:\n",
    "    collection_image_names = os.listdir(address + \"Face Mask Dataset/Train/\" + str(i))\n",
    "    for j in collection_image_names:\n",
    "        img = cv2.imread(address + \"Face Mask Dataset/Train/\" + str(i) + \"/\" + j)\n",
    "        try:\n",
    "            img = cv2.resize(img,(32,32))\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            features.append(img)\n",
    "            if i==\"WithMask\":\n",
    "                target.append(0)\n",
    "            else:\n",
    "                target.append(1)       \n",
    "    print(\"Loaded Folder \",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a86d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "features = np.array(features)\n",
    "target = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41961825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    image = image/225\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b790885",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(list(map(preprocessing,features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202e650d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a16fc37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_features,test_features,train_target,test_target = train_test_split(features,target,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16107bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 32, 32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "903f856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.reshape(8000,32,32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4e66ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b25054b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7136b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGen = ImageDataGenerator(rotation_range=10,width_shift_range=0.1,height_shift_range=0.1,zoom_range=0.2,shear_range=0.1)\n",
    "dataGen.fit(train_features)\n",
    "batches = dataGen.flow(train_features,train_target,batch_size=20)\n",
    "images,labels = next(batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6af460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b758347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 32, 32, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e2329fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.reshape(20,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee598d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1245af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c35c7305",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0cef512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "train_target = to_categorical(train_target)\n",
    "train_target.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1e94a3",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06d0689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,MaxPooling2D,Conv2D,Flatten,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8456c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(100, (3,3), activation='relu', input_shape = (32,32,1)))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(30,(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(2,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf7cd9f",
   "metadata": {},
   "source": [
    "# Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a49abf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(Adam(learning_rate=0.001),loss = \"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a90eaa",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f7e9b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "200/200 [==============================] - 35s 167ms/step - loss: 0.3729 - accuracy: 0.8152 - val_loss: 0.2330 - val_accuracy: 0.9069\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 0.1931 - accuracy: 0.9291 - val_loss: 0.1575 - val_accuracy: 0.9525\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 0.1388 - accuracy: 0.9495 - val_loss: 0.0949 - val_accuracy: 0.9712\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1224 - accuracy: 0.9569 - val_loss: 0.1265 - val_accuracy: 0.9525\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 0.1098 - accuracy: 0.9581 - val_loss: 0.0738 - val_accuracy: 0.9744\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.0981 - accuracy: 0.9653 - val_loss: 0.0757 - val_accuracy: 0.9725\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 0.0869 - accuracy: 0.9716 - val_loss: 0.0777 - val_accuracy: 0.9719\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 0.0741 - accuracy: 0.9728 - val_loss: 0.0738 - val_accuracy: 0.9756\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 29s 146ms/step - loss: 0.0784 - accuracy: 0.9716 - val_loss: 0.0541 - val_accuracy: 0.9806\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 0.0727 - accuracy: 0.9759 - val_loss: 0.0612 - val_accuracy: 0.9787\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 0.0611 - accuracy: 0.9767 - val_loss: 0.0607 - val_accuracy: 0.9787\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.0597 - accuracy: 0.9783 - val_loss: 0.0463 - val_accuracy: 0.9844\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0559 - accuracy: 0.9792 - val_loss: 0.0487 - val_accuracy: 0.9825\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 29s 146ms/step - loss: 0.0619 - accuracy: 0.9767 - val_loss: 0.0643 - val_accuracy: 0.9756\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.0575 - accuracy: 0.9784 - val_loss: 0.0535 - val_accuracy: 0.9769\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.0517 - accuracy: 0.9808 - val_loss: 0.1102 - val_accuracy: 0.9569\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.0464 - accuracy: 0.9834 - val_loss: 0.0672 - val_accuracy: 0.9769\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 29s 146ms/step - loss: 0.0405 - accuracy: 0.9858 - val_loss: 0.0469 - val_accuracy: 0.9869\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.0411 - accuracy: 0.9848 - val_loss: 0.0375 - val_accuracy: 0.9869\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0349 - accuracy: 0.9866 - val_loss: 0.0404 - val_accuracy: 0.9862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24d8a6e0400>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_features,train_target,epochs=20,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf701d18",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb074029",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"C:/Users/91808/Downloads/SPK IIIT/internships and courses/python/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c22608",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ModelInJson = model.to_json()\n",
    "abc = open(location + \"files for mask detector model/model_mask_detector2.json\",\"w\")\n",
    "abc.write(ModelInJson)\n",
    "\n",
    "model.save_weights(location + \"files for mask detector model/model_mask_detector2_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231ad1d0",
   "metadata": {},
   "source": [
    "# Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "509c0892",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"C:/Users/91808/Downloads/SPK IIIT/internships and courses/python/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e8c05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "abc = open(location + \"files for mask detector model/model_mask_detector2.json\",\"r\")\n",
    "loaded_data = abc.read()\n",
    "loaded_model = model_from_json(loaded_data)\n",
    "loaded_model.load_weights(location + \"files for mask detector model/model_mask_detector2_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220cef8b",
   "metadata": {},
   "source": [
    "# Testing The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1724a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassName(classNo):\n",
    "    if classNo == 0:    return \"YES\"\n",
    "    elif classNo == 1:  return \"NO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de11c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "capt = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "while True:\n",
    "    msg,image = capt.read()\n",
    "    face_cascade = cv2.CascadeClassifier(location + \"haarcascade_frontalface_default.xml\")\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray,scaleFactor = 1.3,minNeighbors = 5)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(image,(x,y-50),(x+w, y+h+10), (255,0,0),2)\n",
    "        face_image = gray[y:y+h, x:x+w]\n",
    "        resize = cv2.resize(face_image,(32,32))\n",
    "        normalized = resize/225.0\n",
    "        reshaped = np.reshape(normalized,(1,32,32,1))\n",
    "        prediction = loaded_model.predict(reshaped)\n",
    "        neuron_index = loaded_model.predict_classes(reshaped)\n",
    "        \n",
    "        cv2.putText(image,\"Mask: \",(20,35),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,225),2)\n",
    "        cv2.putText(image,\"Probablity: \",(20,75),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,225),2)\n",
    "        ProbabilityValue = np.amax(prediction)\n",
    "        if ProbabilityValue> 0.25:\n",
    "            cv2.putText(image,getClassName(neuron_index),(120,35),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,225),2)\n",
    "            cv2.putText(image,str(int(ProbabilityValue*100)) + \"%\",(200,75),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,225),2)\n",
    "    cv2.imshow('MASK DETECTOR', cv2.resize(image,(1600,960),interpolation = cv2.INTER_CUBIC))\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc0adb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21376c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbeee6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2b3658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
